}
predict_mod <- function(obs, response, weights){
# Predicting observations using pre-calculated weights
num_features <- colnames(obs)[unname(sapply(obs,is.numeric))]  # Numeric variables only
num_features <- num_features[num_features != response]  # Excluding response variable
N <- nrow(obs)  # Number of observations
p <- length(num_features)  # Number of input variables
X <- as.matrix(obs[,num_features])  # Transforming into matrix
X <- cbind(rep(1,N),X)  # Adding intercept (bias)
predicted <- X %*% weights
return(predicted)
}
cross_val <- function(data, response, exact=T, speed=0.6){
# Cross validation: leave one out
init <- rep(NA,nrow(data))  #  initializing df for cross-val. output
accuracy <- data.frame(sq_err=init, pred=init)
weight_list <- list()
for(i in 1:nrow(data)){  # Leave one out (each obs once)
trained <- train_mod(data[-i,], response, exact, speed)  # Training without obs i
test_obs <- predict_mod(data[i,], response, trained$weights)  # Predicting val i
sq_err <- (as.numeric(test_obs) - as.numeric(data[i,response]))^2
# computing sqared error from real value
weight_list[[i]] <- trained$weights
accuracy[i,] <- c(sq_err, test_obs)
}
return(list(accuracy=accuracy, weights=weight_list))
}
# Playing with model
# Predicting quantitative variable
out_var='Petal.Length'
results <-cross_val(iris,out_var,exact=F,speed=0.0006)
plot(as.numeric(iris[,out_var]),results$accuracy$pred)
plot(density(results$accuracy$sq_err))
boxplot(t(do.call(cbind,results$weights)))
# Plotting variation of weights and intercept
# ----------
# Predicting categorical variable
out_var<- 'Species'
results <- cross_val(iris, out_var)
plot(as.numeric(iris[,out_var]),results$accuracy$pred)
abline(h=c(1.5,2.5),col="red")
length(iris$Species[round(results$accuracy$pred)==as.numeric(iris[,out_var])])/nrow(iris)
# Plotting variation of weights and intercept
fitted_lines <- t(do.call(cbind,results$weights))
boxplot(fitted_lines)
par(mfrow=c(2,2))
for(b in 2:5){
# Fitted curves produced by LOO cross-val. on every axis
plot(seq(1,20,4),seq(1,5),type='n')
for(r in 1:nrow(fitted_lines)){
abline(a = fitted_lines[r,1],b=fitted_lines[r,b])
}
}
results <- cross_val(iris, out_var, exact=F, speed=0.0006)
plot(as.numeric(iris[,out_var]),results$accuracy$pred)
abline(h=c(1.5,2.5),col="red")
length(iris$Species[round(results$accuracy$pred)==as.numeric(iris[,out_var])])/nrow(iris)
results$accuracy
results$weights
df = iris
response=out_var
num_features <- colnames(df)[unname(sapply(df,is.numeric))]  # Numeric variables only
num_features <- num_features[num_features != response]  # Excluding response variable
N <- nrow(df)  # Number of observations
p <- length(num_features)  # Number of input variables
X <- as.matrix(df[,num_features])  # Transforming into matrix
X <- cbind(rep(1,N),X)  # Adding intercept (bias)
df[,response] <- as.numeric(df[,response])  # If response is factorial, encoded with integers
Y <- as.matrix(df[,response])  # Response variable as matrix
X %*% B_hat
B_hat <- matrix(rep(1,p+1),ncol=1)  # Initiating weights
X %*% B_hat
X
X %*% B_hat
(2/N) * (t((Y - Y_hat)) %*% X)
Y_hat <- X %*% B_hat  # Computing estimated response from weights
(2/N) * (t((Y - Y_hat)) %*% X)
plot.new()
# Just writing a linear model with cross validation from scratch for training.
train_mod <- function(df, response, exact=T,speed=0.6, plot=F){
# Takes a dataframe and the name of the variable to predict as input.
# Returns the input dataframe with the estimated age after minimizing RSS
num_features <- colnames(df)[unname(sapply(df,is.numeric))]  # Numeric variables only
num_features <- num_features[num_features != response]  # Excluding response variable
N <- nrow(df)  # Number of observations
p <- length(num_features)  # Number of input variables
X <- as.matrix(df[,num_features])  # Transforming into matrix
X <- cbind(rep(1,N),X)  # Adding intercept (bias)
df[,response] <- as.numeric(df[,response])  # If response is factorial, encoded with integers
Y <- as.matrix(df[,response])  # Response variable as matrix
# Plotting input-response correlations
if(plot==T){
par(mfrow=c(floor(sqrt(p)),p/floor(sqrt(p))))
for(var in num_features){plot(df[,var],df[,response],main=var)}
}
if(exact==T){
# Solution of the derivative by beta to minimize RSS(B)
B_hat <- solve(t(X)%*%X) %*% t(X) %*% Y
Y_hat <- X %*% B_hat
} else{
# Using gradient descent method. Approximate solution, but
# faster in very high dimensional space with many observations
B_hat <- matrix(rep(1,p+1),ncol=1)  # Initiating weights
for(i in 1:200){
Y_hat <- X %*% B_hat  # Computing estimated response from weights
gradients <- (2/N) * (t((Y_hat - Y)) %*% X)
# Using partial derivative of each weight to compute gradient
B_hat <- B_hat - t(gradients) * speed  # Updating weights using gradients
}
Y_hat <- X %*% B_hat
}
df_out <- cbind(df, Y_hat)
return(list(table=df_out,weights=B_hat))
}
predict_mod <- function(obs, response, weights){
# Predicting observations using pre-calculated weights
num_features <- colnames(obs)[unname(sapply(obs,is.numeric))]  # Numeric variables only
num_features <- num_features[num_features != response]  # Excluding response variable
N <- nrow(obs)  # Number of observations
p <- length(num_features)  # Number of input variables
X <- as.matrix(obs[,num_features])  # Transforming into matrix
X <- cbind(rep(1,N),X)  # Adding intercept (bias)
predicted <- X %*% weights
return(predicted)
}
cross_val <- function(data, response, exact=T, speed=0.6){
# Cross validation: leave one out
init <- rep(NA,nrow(data))  #  initializing df for cross-val. output
accuracy <- data.frame(sq_err=init, pred=init)
weight_list <- list()
for(i in 1:nrow(data)){  # Leave one out (each obs once)
trained <- train_mod(data[-i,], response, exact, speed)  # Training without obs i
test_obs <- predict_mod(data[i,], response, trained$weights)  # Predicting val i
sq_err <- (as.numeric(test_obs) - as.numeric(data[i,response]))^2
# computing sqared error from real value
weight_list[[i]] <- trained$weights
accuracy[i,] <- c(sq_err, test_obs)
}
return(list(accuracy=accuracy, weights=weight_list))
}
# Playing with model
# Predicting quantitative variable
out_var='Petal.Length'
results <-cross_val(iris,out_var,exact=F,speed=0.0006)
plot(as.numeric(iris[,out_var]),results$accuracy$pred)
plot(density(results$accuracy$sq_err))
boxplot(t(do.call(cbind,results$weights)))
# Plotting variation of weights and intercept
# ----------
# Predicting categorical variable
out_var<- 'Species'
results <- cross_val(iris, out_var, exact=F, speed=0.0006)
plot(as.numeric(iris[,out_var]),results$accuracy$pred)
abline(h=c(1.5,2.5),col="red")
length(iris$Species[round(results$accuracy$pred)==as.numeric(iris[,out_var])])/nrow(iris)
# Plotting variation of weights and intercept
fitted_lines <- t(do.call(cbind,results$weights))
boxplot(fitted_lines)
par(mfrow=c(2,2))
for(b in 2:5){
# Fitted curves produced by LOO cross-val. on every axis
plot(seq(1,20,4),seq(1,5),type='n')
for(r in 1:nrow(fitted_lines)){
abline(a = fitted_lines[r,1],b=fitted_lines[r,b])
}
}
boxplot(fitted_lines)
out_var<- 'Species'
results <- cross_val(iris, out_var, exact=F, speed=0.0006)
plot(as.numeric(iris[,out_var]),results$accuracy$pred)
abline(h=c(1.5,2.5),col="red")
length(iris$Species[round(results$accuracy$pred)==as.numeric(iris[,out_var])])/nrow(iris)
train_mod <- function(df, response, exact=T,speed=0.6, plot=F){
# Takes a dataframe and the name of the variable to predict as input.
# Returns the input dataframe with the estimated age after minimizing RSS
num_features <- colnames(df)[unname(sapply(df,is.numeric))]  # Numeric variables only
num_features <- num_features[num_features != response]  # Excluding response variable
N <- nrow(df)  # Number of observations
p <- length(num_features)  # Number of input variables
X <- as.matrix(df[,num_features])  # Transforming into matrix
X <- cbind(rep(1,N),X)  # Adding intercept (bias)
df[,response] <- as.numeric(df[,response])  # If response is factorial, encoded with integers
Y <- as.matrix(df[,response])  # Response variable as matrix
# Plotting input-response correlations
if(plot==T){
par(mfrow=c(floor(sqrt(p)),p/floor(sqrt(p))))
for(var in num_features){plot(df[,var],df[,response],main=var)}
}
if(exact==T){
# Solution of the derivative by beta to minimize RSS(B)
B_hat <- solve(t(X)%*%X) %*% t(X) %*% Y
Y_hat <- X %*% B_hat
} else{
# Using gradient descent method. Approximate solution, but
# faster in very high dimensional space with many observations
B_hat <- matrix(rep(1,p+1),ncol=1)  # Initiating weights
for(i in 1:2000){
Y_hat <- X %*% B_hat  # Computing estimated response from weights
gradients <- (2/N) * (t((Y_hat - Y)) %*% X)
# Using partial derivative of each weight to compute gradient
B_hat <- B_hat - t(gradients) * speed  # Updating weights using gradients
}
Y_hat <- X %*% B_hat
}
df_out <- cbind(df, Y_hat)
return(list(table=df_out,weights=B_hat))
}
out_var<- 'Species'
results <- cross_val(iris, out_var, exact=F, speed=0.0006)
length(iris$Species[round(results$accuracy$pred)==as.numeric(iris[,out_var])])/nrow(iris)
# Just writing a linear model with cross validation from scratch for training.
train_mod <- function(df, response, exact=T,speed=0.6, iter=200, plot=F){
# Takes a dataframe and the name of the variable to predict as input.
# Returns the input dataframe with the estimated age after minimizing RSS
num_features <- colnames(df)[unname(sapply(df,is.numeric))]  # Numeric variables only
num_features <- num_features[num_features != response]  # Excluding response variable
N <- nrow(df)  # Number of observations
p <- length(num_features)  # Number of input variables
X <- as.matrix(df[,num_features])  # Transforming into matrix
X <- cbind(rep(1,N),X)  # Adding intercept (bias)
df[,response] <- as.numeric(df[,response])  # If response is factorial, encoded with integers
Y <- as.matrix(df[,response])  # Response variable as matrix
# Plotting input-response correlations
if(plot==T){
par(mfrow=c(floor(sqrt(p)),p/floor(sqrt(p))))
for(var in num_features){plot(df[,var],df[,response],main=var)}
}
if(exact==T){
# Solution of the derivative by beta to minimize RSS(B)
B_hat <- solve(t(X)%*%X) %*% t(X) %*% Y
Y_hat <- X %*% B_hat
} else{
# Using gradient descent method. Approximate solution, but
# faster in very high dimensional space with many observations
B_hat <- matrix(rep(1,p+1),ncol=1)  # Initiating weights
for(i in 1:iter){
Y_hat <- X %*% B_hat  # Computing estimated response from weights
gradients <- (2/N) * (t((Y_hat - Y)) %*% X)
# Using partial derivative of each weight to compute gradient
B_hat <- B_hat - t(gradients) * speed  # Updating weights using gradients
}
Y_hat <- X %*% B_hat
}
df_out <- cbind(df, Y_hat)
return(list(table=df_out,weights=B_hat))
}
predict_mod <- function(obs, response, weights){
# Predicting observations using pre-calculated weights
num_features <- colnames(obs)[unname(sapply(obs,is.numeric))]  # Numeric variables only
num_features <- num_features[num_features != response]  # Excluding response variable
N <- nrow(obs)  # Number of observations
p <- length(num_features)  # Number of input variables
X <- as.matrix(obs[,num_features])  # Transforming into matrix
X <- cbind(rep(1,N),X)  # Adding intercept (bias)
predicted <- X %*% weights
return(predicted)
}
cross_val <- function(data, response, exact=T, speed=0.6, iter=200){
# Cross validation: leave one out
init <- rep(NA,nrow(data))  #  initializing df for cross-val. output
accuracy <- data.frame(sq_err=init, pred=init)
weight_list <- list()
for(i in 1:nrow(data)){  # Leave one out (each obs once)
trained <- train_mod(data[-i,], response, exact, speed, iter)  # Training without obs i
test_obs <- predict_mod(data[i,], response, trained$weights)  # Predicting val i
sq_err <- (as.numeric(test_obs) - as.numeric(data[i,response]))^2
# computing sqared error from real value
weight_list[[i]] <- trained$weights
accuracy[i,] <- c(sq_err, test_obs)
}
return(list(accuracy=accuracy, weights=weight_list))
}
# Playing with model
# Predicting quantitative variable
out_var='Petal.Length'
results <-cross_val(iris,out_var,exact=F,speed=0.0006, iter=2000)
plot(as.numeric(iris[,out_var]),results$accuracy$pred)
plot(density(results$accuracy$sq_err))
boxplot(t(do.call(cbind,results$weights)))
# Plotting variation of weights and intercept
# ----------
# Predicting categorical variable
out_var<- 'Species'
results <- cross_val(iris, out_var, exact=F, speed=0.0006, iter=1000)
plot(as.numeric(iris[,out_var]),results$accuracy$pred)
abline(h=c(1.5,2.5),col="red")
length(iris$Species[round(results$accuracy$pred)==as.numeric(iris[,out_var])])/nrow(iris)
# Plotting variation of weights and intercept
fitted_lines <- t(do.call(cbind,results$weights))
boxplot(fitted_lines)
par(mfrow=c(2,2))
for(b in 2:5){
# Fitted curves produced by LOO cross-val. on every axis
plot(seq(1,20,4),seq(1,5),type='n')
for(r in 1:nrow(fitted_lines)){
abline(a = fitted_lines[r,1],b=fitted_lines[r,b])
}
}
length(iris$Species[round(results$accuracy$pred)==as.numeric(iris[,out_var])])/nrow(iris)
results <- cross_val(iris, out_var, exact=F, speed=0.006, iter=1000)
length(iris$Species[round(results$accuracy$pred)==as.numeric(iris[,out_var])])/nrow(iris)
results <- cross_val(iris, out_var, exact=F, speed=0.006, iter=10000)
length(iris$Species[round(results$accuracy$pred)==as.numeric(iris[,out_var])])/nrow(iris)
for(i in 1:200){
results <- cross_val(iris, out_var, exact=F, speed=0.006, iter=1000)
length(iris$Species[round(results$accuracy$pred)==as.numeric(iris[,out_var])])/nrow(iris)
}
out_var<- 'Species'
correct <- c()
for(i in 1:200){
results <- cross_val(iris, out_var, exact=F, speed=0.006, iter=i)
acc <- length(iris$Species[round(results$accuracy$pred)==
as.numeric(iris[,out_var])])/nrow(iris)
correct <- append(correct, acc)
}
plot(1:158, correct)
results <-cross_val(iris,out_var,exact=F,speed=0.0006, iter=200)
boxplot(t(do.call(cbind,results$weights)))
results <-cross_val(iris,out_var,exact=F,speed=0.0006, iter=200)
boxplot(t(do.call(cbind,results$weights)))
par(mfrow=c(1,2))
y
boxplot(t(do.call(cbind,results$weights)))
results <-cross_val(iris,out_var,exact=T)
boxplot(t(do.call(cbind,results$weights)))
results <- cross_val(iris, out_var, exact=F, speed=0.006, iter=100)
plot(as.numeric(iris[,out_var]),results$accuracy$pred)
out_var='Petal.Length'
results <-cross_val(iris,out_var,exact=F,speed=0.0006, iter=200)
plot(as.numeric(iris[,out_var]),results$accuracy$pred)
plot(density(results$accuracy$sq_err))
boxplot(t(do.call(cbind,results$weights)))
train_mod <- function(df, response, exact=T,speed=0.6, iter=200, plot=F){
# Takes a dataframe and the name of the variable to predict as input.
# Returns the input dataframe with the estimated age after minimizing RSS
num_features <- colnames(df)[unname(sapply(df,is.numeric))]  # Numeric variables only
num_features <- num_features[num_features != response]  # Excluding response variable
N <- nrow(df)  # Number of observations
p <- length(num_features)  # Number of input variables
X <- as.matrix(df[,num_features])  # Transforming into matrix
X <- cbind(rep(1,N),X)  # Adding intercept (bias)
df[,response] <- as.numeric(df[,response])  # If response is factorial, encoded with integers
Y <- as.matrix(df[,response])  # Response variable as matrix
# Plotting input-response correlations
if(plot==T){
par(mfrow=c(floor(sqrt(p)),p/floor(sqrt(p))))
for(var in num_features){plot(df[,var],df[,response],main=var)}
}
if(exact==T){
# Solution of the derivative by beta to minimize RSS(B)
B_hat <- solve(t(X)%*%X) %*% t(X) %*% Y
} else{
# Using gradient descent method. Approximate solution, but
# faster in very high dimensional space with many observations
B_hat <- matrix(rep(1,p+1),ncol=1)  # Initiating weights
for(i in 1:iter){
Y_hat <- X %*% B_hat  # Computing estimated response from weights
gradients <- (2/N) * (t((Y_hat - Y)) %*% X)
# Using partial derivative of each weight to compute gradient
B_hat <- B_hat - t(gradients) * speed  # Updating weights using gradients
}
}
Y_hat <- X %*% B_hat
df_out <- cbind(df, Y_hat)
return(list(table=df_out,weights=B_hat))
}
out_var='Petal.Length'
results <-cross_val(iris,out_var,exact=F,speed=0.0006, iter=200)
results
plot(as.numeric(iris[,out_var]),results$accuracy$pred)
plot(density(results$accuracy$sq_err))
par(mfrow=c(1,2))
out_var='Petal.Length'
results <-cross_val(iris,out_var,exact=F,speed=0.0006, iter=200)
plot(density(results$accuracy$sq_err))
results <-cross_val(iris,out_var,exact=T)
plot(density(results$accuracy$sq_err))
results <-cross_val(iris,out_var,exact=F,speed=0.0006, iter=2000)
plot(density(results$accuracy$sq_err))
results <-cross_val(iris,out_var,exact=T)
boxplot(t(do.call(cbind,results$weights)))
plot(density(results$accuracy$sq_err))
results <-cross_val(iris,out_var,exact=F,speed=0.0006, iter=200)
plot(as.numeric(iris[,out_var]),results$accuracy$pred)
boxplot(t(do.call(cbind,results$weights)))
results <-cross_val(iris,out_var,exact=F,speed=0.0006, iter=20)
boxplot(t(do.call(cbind,results$weights)))
results <-cross_val(iris,out_var,exact=T)
boxplot(t(do.call(cbind,results$weights)))
results <-cross_val(iris,out_var,exact=F,speed=0.0006, iter=20)
results$weights
plot(density(results$accuracy$sq_err))
results <-cross_val(iris,out_var,exact=F,speed=0.0006, iter=20)
t(do.call(cbind,results$weights))
results <-cross_val(iris,out_var,exact=T)
t(do.call(cbind,results$weights))
results <- cross_val(iris, out_var, exact=F, speed=0.6, iter=100)
out_var<- 'Species'
results <- cross_val(iris, out_var, exact=F, speed=0.6, iter=100)
boxplot(fitted_lines)
length(iris$Species[round(results$accuracy$pred)==as.numeric(iris[,out_var])])/nrow(iris)
plot(as.numeric(iris[,out_var]),results$accuracy$pred)
abline(h=c(1.5,2.5),col="red")
out_var<- 'Species'
results <- cross_val(iris, out_var, exact=F, speed=0.0006, iter=100)
plot(as.numeric(iris[,out_var]),results$accuracy$pred)
abline(h=c(1.5,2.5),col="red")
length(iris$Species[round(results$accuracy$pred)==as.numeric(iris[,out_var])])/nrow(iris)
results <- cross_val(iris, out_var, exact=F, speed=0.006, iter=100)
plot(as.numeric(iris[,out_var]),results$accuracy$pred)
abline(h=c(1.5,2.5),col="red")
length(iris$Species[round(results$accuracy$pred)==as.numeric(iris[,out_var])])/nrow(iris)
results <- cross_val(iris, out_var, exact=F, speed=0.06, iter=100)
plot(as.numeric(iris[,out_var]),results$accuracy$pred)
abline(h=c(1.5,2.5),col="red")
length(iris$Species[round(results$accuracy$pred)==as.numeric(iris[,out_var])])/nrow(iris)
par(mfrow=c(3,1))
out_var<- 'Species'
results <- cross_val(iris, out_var, exact=F, speed=0.006, iter=10)
plot(as.numeric(iris[,out_var]),results$accuracy$pred)
abline(h=c(1.5,2.5),col="red")
par(mfrow=c(1,3))
out_var<- 'Species'
results <- cross_val(iris, out_var, exact=F, speed=0.006, iter=10)
plot(as.numeric(iris[,out_var]),results$accuracy$pred)
abline(h=c(1.5,2.5),col="red")
results <- cross_val(iris, out_var, exact=F, speed=0.006, iter=100)
plot(as.numeric(iris[,out_var]),results$accuracy$pred)
abline(h=c(1.5,2.5),col="red")
results <- cross_val(iris, out_var, exact=F, speed=0.006, iter=1000)
plot(as.numeric(iris[,out_var]),results$accuracy$pred)
abline(h=c(1.5,2.5),col="red")
out_var<- 'Species'
results <- cross_val(iris, out_var, exact=F, speed=0.006, iter=100)
plot(as.numeric(iris[,out_var]),results$accuracy$pred)
abline(h=c(1.5,2.5),col="red")
length(iris$Species[round(results$accuracy$pred)==as.numeric(iris[,out_var])])/nrow(iris)
# Plotting variation of weights and intercept
fitted_lines <- t(do.call(cbind,results$weights))
boxplot(fitted_lines)
par(mfrow=c(2,2))
for(b in 2:5){
# Fitted curves produced by LOO cross-val. on every axis
plot(seq(1,20,4),seq(1,5),type='n')
for(r in 1:nrow(fitted_lines)){
abline(a = fitted_lines[r,1],b=fitted_lines[r,b])
}
}
par(mfrow=c(2,2))
for(b in 2:5){
# Fitted curves produced by LOO cross-val. on every axis
plot(seq(1,20,4),seq(1,50),type='n')
for(r in 1:nrow(fitted_lines)){
abline(a = fitted_lines[r,1],b=fitted_lines[r,b])
}
}
par(mfrow=c(2,2))
for(b in 2:5){
# Fitted curves produced by LOO cross-val. on every axis
plot(seq(1,200,4),seq(1,50),type='n')
for(r in 1:nrow(fitted_lines)){
abline(a = fitted_lines[r,1],b=fitted_lines[r,b])
}
}
plot(density(results$accuracy$sq_err),pch=9)
boxplot(t(do.call(cbind,results$weights)),,pch=9)
boxplot(t(do.call(cbind,results$weights)),pch=10)
boxplot(t(do.call(cbind,results$weights)),pch=3)
boxplot(t(do.call(cbind,results$weights)),pch=4)
boxplot(t(do.call(cbind,results$weights)),pch=5)
boxplot(t(do.call(cbind,results$weights)),pch=6)
boxplot(t(do.call(cbind,results$weights)),pch=6)
t(do.call(cbind,results$weights))
par(mfrow=c(2,2))
for(b in 2:5){
# Fitted curves produced by LOO cross-val. on every axis
plot(seq(1,200,4),seq(1,50),type='n')
for(r in 1:nrow(fitted_lines)){
abline(a = fitted_lines[r,1],b=fitted_lines[r,b])
}
}
out_var='Petal.Length'
results <-cross_val(iris,out_var,exact=F,speed=0.0006, iter=20)
results <-cross_val(iris,out_var,exact=T)
for(b in 2:5){
# Fitted curves produced by LOO cross-val. on every axis
plot(seq(1,200,4),seq(1,50),type='n')
for(r in 1:nrow(fitted_lines)){
abline(a = fitted_lines[r,1],b=fitted_lines[r,b])
}
}
results <-cross_val(iris,out_var,exact=T)
for(b in 2:5){
# Fitted curves produced by LOO cross-val. on every axis
plot(seq(1,200,4),seq(1,50),type='n')
for(r in 1:nrow(fitted_lines)){
abline(a = fitted_lines[r,1],b=fitted_lines[r,b])
}
}
out_var='Petal.Length'
results <-cross_val(iris,out_var,exact=F,speed=0.0006, iter=20)
results <-cross_val(iris,out_var,exact=T)
fitted_lines <- t(do.call(cbind,results$weights))
boxplot(fitted_lines)
par(mfrow=c(2,2))
for(b in 2:5){
# Fitted curves produced by LOO cross-val. on every axis
plot(seq(1,200,4),seq(1,50),type='n')
for(r in 1:nrow(fitted_lines)){
abline(a = fitted_lines[r,1],b=fitted_lines[r,b])
}
}
